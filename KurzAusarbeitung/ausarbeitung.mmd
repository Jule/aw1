Base Header Level:  3

# Thematic overview

As modern embedded applications evolve, their performance requirements increase. Due to the limitations of embedded platforms, such as constraints in power consumption and heat dissipation, these increased performance requirements cannot be met by increasing processor clock rates. Consequently, modern embedded processors, such as the Dual Core ARM Cortex-A9 shipped on the Xilinx Zynq platform, do not only feature more than a single processing core, but also provide support for hardware level parallelism. "Single Instruction - Multiple Data" (SIMD) techniques, which are especially well suited for media and signal processing <!--\citep{Kejariwal2009}-->, are an example of hardware parallelism support. Since it is not generally possible to automatically parallelize existing applications, they need to be redesigned to take advantage of the platform enhancements.

The process of (re-)designing an application for parallelism involves finding *exploitable concurrency*, by analyzing the problem at hand, decomposing it into subproblems that can **safely execute at the same time**. Based on these subproblems, a parallel algorithm can be designed and implemented <!--\citep{Mattson2010}-->. In the context of the <!--\citet{FAUST2013}-->, a specific embedded application in need of parallelization is an obstacle detection system in cooperation with a lane guiding control (depicted in <!--\autoref{fig:application}-->). Evaluating the distance data measured by a laser scanner and the image stream providing extracted road marking parameters constitues a dataflow parallelization problem, for which suitable algorithms must be researched and compared. A promising approach is the use of pipeline parallelism (as provided by OpenMP), in which the computation steps are divided into "stages" that are executed on different CPU cores, thus building a "computation pipeline" <!--\citep{PreudHomme2012}-->. To further increase performance of the pipeline, the already mentioned SIMD instructions can be used.

The Go programming language was conceived, among other things, to allow for a highly productive development environment for parallel applications. While it is certainly possible to write concurrent applications in many of the programming languages widely in use today, very few of them were specifically built around the concept of concurrency <!--\citep{Pike2012}-->. The hypothesis is thus, that by using the Go programming language to develop parallel applications on embedded platforms, one can increase developer productiveness by allowing the language to take care of tasks such as thread scheduling and memory management. Given that said features come at the cost of performance, another hypothesis that requires confirmation is that the overhead that the usage of Go introduces on an embedded platform is insignificant compared to the benefit that its usage provides.

In the course of my master seminar, these hypotheses will be evaluated by extracting performance critical elements from the mentioned FAUST application and implementing them in Go and C, using state of the art  dataflow parallelization algorithms. These implementations will then be compared to their original (non-parallelized) counterparts, in terms of performance, ease of implementation and implementation complexity.

<!--
\clearpage
%\figur{width=0.9\textwidth}{ZynqPlatformAnwendung}{Obstacle detection on the Zynq Platform}{fig:application}

\begin{figure}[htbp]%
\centering%
\includegraphics[keepaspectratio,width=0.9\textwidth]{figures/ZynqPlatformAnwendung}
\caption{Obstacle detection and lane guiding control on the Zynq Platform}
\label{fig:application}
\end{figure}

\bibliography{bibliography/bibliography}
-->
