Base Header Level:  3
latex input:        document-info
latex input:        x3-util
latex footer:       x3-paper-end


<!--\clearpage-->
# Introduction and Motivation

Embedded platforms and applications are being used throughout many industries, including telecommunication, robotics, medical and automotive <!--\citep{Wang2013}-->. <!--\citet{Campeanu2013}--> states that nowadays it is increasingly common to build embedded systems on heterogenous platforms, containing multiple computational units such as multi-core CPUs, GPUs and FPGAs. If all these components are used to the full extent of their capabilities, such a setup enables better performance than could be previously achieved on embedded platforms.

This is an important shift, since applications running on these platforms become more and more complex, and their performance requirements have to be satisfied. In the past, not only on embedded platforms, this was commonly achieved by boosting processor clock rates. But due to both intractable physical limitations as well as practical engineering considerations, increasing processor clock rates is no longer a feasible approach <!--\citep{Cantrill2008}-->.

The performance gains possible on heterogenous embedded platforms are a result of the hardware-level parallelism that is achievable on these platforms. But unfortunately, exploiting these parallelism features still is a considerable challenge, given the tools and programming concepts widely in use today <!--\citep{Wang2013,Cantrill2008}-->.

Because of the mentioned increase in complexity and performance requirements in embedded applications, and considering that clock rates can't be expected to increase significantly anymore, research in the area of concurrent applications has taken an important place in the computer science research community. This can be seen in <!--\autoref{fig:concurrency-publications}-->, which shows an increasing number of publications related to concurrency over the last years.

<!--\fig{concurrency-publications}{A strong increase in publications related to concurrency can be observed over the last years.}-->


In context of the <!--\citet{FAUST2013}--> at the Hamburg University of Applied Sciences, a specific embedded application in need of parallelization is an obstacle detection system in cooperation with a lane guiding control. Evaluating the distance data measured by a laser scanner and the image stream providing extracted road marking parameters constitues a dataflow parallelization problem, for which suitable algorithms must be researched and compared. Therefore, this essay focuses on the literature evaluation of techniques that allow for the exploitation of potential sources of parallelism, especially those which are suitable for dataflow problems. Said evaluation is done in context of a modern multiprocessor system-on-chip platform (MPSoC), the Xilinx Zynq 7000. The goal is to get a broad overview of the state-of-the-art techniques being used, as well as their up- and downsides, especially in resource-constrained environments. Additionally, the current lack of widely used tools and languages crafted for use in concurrent environments is addressed by giving a short overview of the "Go" programming language, and of how it might be used on embedded platforms to increase developer efficiency.

The evaluation is confined to the area of Symmetric Multiprocessor (SMP) systems, i.e. those having multiple processors or processing cores with a shared memory. Other parallelism concepts for architectures such as Distributed Memory Access or Nonuniform Memory Access will not be discussed.

<!--\todoin{Übersicht zu den einzelnen Kapiteln, sodass der rote Faden zu den Zielvorstellungen deutlich wird.}-->

# Parallelism vs. Concurrency
# The Xilinx Zynq Platform

<!--\clearpage-->
# Technique Categorizations

<!--\citet{Flynn1972}-->, in what is often referred to as "Flynn's Taxonomy", states that there are four broad categories of computer architectures:

<!--
\begin{tabular}{ll}
\textbf{SISD} & Single instruction, single data\\
\textbf{MISD} & Multiple instruction, single data\\
\textbf{SIMD} & Single instruction, multiple data\\
\textbf{MIMD} & Multiple instruction, multiple data\\
\end{tabular}
-->

SISD is what can be found in most single-core computers, where a single stream of input data is processed by a single stream of instructions. SISD is not further discussed since it has no parallel elements, and MISD is completely ommited because there are no well-known systems that fit into this category <!--\citep{Mattson2004}-->.

In this essay, the focus is on SIMD and MIMD architectures, which offer a potentially high degree of parallel execution.



## Multiple Instruction, Multiple Data

The MIMD category in Flynn's taxonmy, as depicted in <!--\autoref{fig:MIMD}-->, features multiple control-units which provide instructions to a number of processors, each with their own data input stream. Additionally, the MIMD processing units may be interconnected. This category is the most general, and applies to all multi-processor system currently available <!--\citep{Mattson2004}-->.

<!--\figw{MIMD}{TODO.}-->



## Single Instruction, Multiple Data

Given a single stream of instructions and multiple streams of data, an SIMD architecture is one that applies each instruction to all of the data streams **in parallel**. This process is visualized in <!--\autoref{fig:SIMD}-->, where there is a single control unit providing the processors with instructions. For every instruction, every processor takes an item out of its own input stream and applies the instruction.

As such, SIMD architectures are a good fit for specialized applications that consist of high data parallelism as well as little interprocess communication. As an example, in digital signal processing, e.g. decoding a video stream, the situation is common that the same operations need to be applied continously to a large stream of data (in case of a 1080p high-quality H.264 movie, the bitrate is usually above 17Mbit/s).

A Graphics Processing Unit (GPU) can be seen as a heavily parallel SIMD system. GPUs usually consist of an array of multiprocessors, each in turn consisting of multiple processing units (ALUs), which all share a single control unit (exactly as depicted in <!--\autoref{fig:SIMD}-->). Each of these ALUs is then able to execute instructions provided by the control unit, potentially providing a many-fold performance increase.

<!--\todoin{How SIMD works on ARM NEON}-->

<!--\fig{SIMD}{Visualization of a Single instruction, multiple data architecture, containing three processing units. Heavily inspired by \citep{Mattson2004}}-->





# Conclusion

<!--\todo{Komprimierte Darstellung der wesentlichen Inhalte}-->



## Outlook

<!--\todo{Ausblick (wie geht es weiter?)}-->




<!--\clearpage-->
# Gliederungshinweise

* Einleitung
    * Thema und dessen Anwendungsfeld bzw. dessen perspektivische Nutzung zur Unterstützung der Motivation.
    * Ziele der Dokumentation und Abgrenzung.
    * Schwerpunkte der Dokumentation.
    * Übersicht zu den einzelnen Kapiteln, sodass der rote Faden zu den Zielvorstellungen deutlich wird.
* Hauptteil
    * Praktischen oder ggf. wissenschaftlichen Relevanz des Themas
    * Die Begründung für die Struktur und Inhalte der folgenden Kapitel soll vermittelt
    werden.
    * Die Position der Einzelkapitel im Rahmen der Gesamtdarstellung mit deren
    * Bedeutung für den Themenschwerpunkt ist zu verdeutlichen.

    * Jedes Kapitel beginnt mit einer Übersicht zu den zu erwartenden Beiträgen. Fakten, Begründungen, Implikationen und Alternativenvergleiche sind im Vorrang zu Bewertungen und Stellungnahmen zu behandeln.
    * Diskussion der Literatur
    * Die beabsichtigten weiteren Recherchen, theoretischen Analysen, zu erstellende Konzepte und Implementierungen sind zu skizzieren. Eine Einordnung und Gewichtung des im Vortrag behandelten Themas in die voraussichtliche Masterarbeit ist anzustreben.




<!--
% Bibliography
\clearpage
{
    \bibliography{bibliography}
}
-->
